\newcommand{\CLASSINPUTbaselinestretch}{1.0} % baselinestretch
\newcommand{\CLASSINPUTinnersidemargin}{0.75in} % inner side margin
\newcommand{\CLASSINPUToutersidemargin}{0.75in} % outer side margin
\newcommand{\CLASSINPUTtoptextmargin}{0.75in}   % top text margin
\newcommand{\CLASSINPUTbottomtextmargin}{0.75in}% bottom text margin

\newcommand{\revised}[1]{{\color{blue}#1}}

\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts % precisa para usar o \thanks{}
% *** CITATION PACKAGES ***
%
\usepackage{cite}
\usepackage{flushend}
\usepackage{xcolor}
\usepackage[pdftex]{graphicx}

\usepackage[utf8]{inputenc}


% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
\usepackage{amsmath}
\usepackage{amssymb}

% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithm}
\usepackage{algorithmic}

% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
\usepackage{multirow}

% *** SUBFIGURE PACKAGES ***
\usepackage[tight,footnotesize]{subfigure}

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage[bookmarks=false]{hyperref}
\usepackage{url}

% correct bad hyphenation here
\hyphenation{rep-re-sen-ta-tion fe-de-ral}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{\vspace{0.25in}Avaliação estatística sobre seleção de características para categorização de texto}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations

\author{\IEEEauthorblockN{
		Rog\'{e}rio C. P. Fragoso\IEEEauthorrefmark{1}, 
		Saulo C. R. P. Sobrinho\IEEEauthorrefmark{1},
		Lucas F. Melo\IEEEauthorrefmark{1}
}
\IEEEauthorblockA{Universidade Federal de Pernambuco (UFPE), Centro de Inform\'{a}tica (CIn)\\
Av. Jornalista Anibal Fernandes s/n, Cidade Universit\'{a}ria 50740-560, Recife, PE, Brazil\\
rcpf@cin.ufpe.br, lfm2@cin.ufpe.br, scrps@cin.ufpe.br \\}}
%\IEEEauthorrefmark{1}Telephone: +55 81 2126-8430 Ext.4346 Fax: +55 81 2126-8438}}

% make the title area
\maketitle

\begin{abstract}
	%\boldmath
Este trabalho realiza uma análise estatística sobre desempenho de métodos de seleção de características para categorização de texto. Os métodos MFD, MFDR e cMFDR são analisados com objetivo de verificar se a configuração paramétrica automática, fornecida pelo método AFSA, impacta no desempenho de classificação dos métodos. Análises estatísticas não foram conclusivas quanto à aderência das amostras a uma distrbuição normal. Deste modo, o teste de hipóteses não-paramétrico Wilcoxon (teste de sinais com postos).
\end{abstract}

\IEEEpeerreviewmaketitle

% Formato descrito na página da disciplina. Lá ela diz que a presença destas seções é mandatória. 
% (Acho que a gente não precisa organizar nesse formato exatamente, mas precisamos garantir que cada item esteja presente)

%•       Passo 1 – Justificativa: De início, explicitam-se os motivos que justificam a pesquisa, determinando-se e delimitando-se o problema, o qual deve estar formulado de maneira clara e precisa.
%•       Passo 2 - Fundamentação teórica: Descreve-se  o relacionamento do problema com a teoria que será utilizada na pesquisa.
%•       Passo 3 - Objetivo da pesquisa: Os objetivos devem ser retirados diretamente dos problemas levantados no Passo 2. Define-se o que se pretende alcançar com a realização do trabalho.
%•       Passo 4 - Especificação da amostra: Deve-se determinar a área de execução da pesquisa, a população a ser investigada, o tipo de amostra e a determinação do seu tamanho, bem como o tipo de amostragem a ser utilizado. Define-se as variáveis envolvidas.
%•       Passo 5– Análise exploratória: Fazer um estudo descritivo dos dados (gráficos e medidas).  Verificar normalidade dos dados e potenciais pontos aberrantes.
%•       Passo 6– Metodologia (Formulação das hipóteses): Estabelecem-se as hipóteses que serão formuladas, as quais devem ser claras e precisas. Define-se o problema estatisticamente, decidindo-se que informação estatística é realmente necessária e qual método que será aplicado.   
%•       Passo 7 - Análise dos resultados: Passa-se ao tratamento dos dados por intermédio dos testes estatísticos, os quais dependem das hipóteses que serão testadas. Nesse tópico, é exigido que sejam aplicados testes de hipóteses paramétricos e/ou não paramétricos. Testes de duas amostras são exigidos, quando comparando abordagens.

\section{Introdução}
\label{sec:intro}

Um grande problema dos algoritmos de seleção de características é a identificação do número ideal de características a serem selecionadas. Um número pequeno pode acarretar em baixo desempenho de classificação. Um número grande, por outro lado, pode levar a um alto custo computacional. Normalmente este número é encontrado de maneira empíraca. Entretanto, problemas de categorização de texto costumam ser de alta dimensionalidade. Assim, o processo de encontrar o número ideal de características a serem selecionadas pode ser lento e custoso.

Os métodos de seleção de características \textit{Maximum f features per Document} (MFD)~\cite{mfd2014}, \textit{Maximum f features per Document-Reduced} (MFDR)~\cite{mfd2014} e \textit{Class-dependent Maximum f features per Document-Reduced} (cMFDR)~\cite{fragoso2016cmfdr} introduzem uma abordagem de seleção local de características,  o que facilita a parametrização da quantidade de características a serem selecionadas. Em um estudo~\cite{mfd2014}, verificou-se que, com a abordagem tradicional de seleção de características, é necessário avaliar subconjuntos desde 11 características até mais de 5000. Com a abordagem de seleção local, proposta nos métodos aupracitados, o melhor desempenho de classificação é encontrado em um espaço de 10 valores para seu único parâmetro ($f$). 

Todavia, ainda assim, esta parametrização necessita de uma interação manual. Assim, dependendo do tipo de aplicação em que será usado o método de seleção de características, esta parametrização pode ter custos indesejáveis. O método \textit{Automatic Feature Subsets Analyzer} (ASFA)~\cite{fragoso2016afsa} foi proposto para tratar deste problema. AFSA realiza automaticamente a parametrização dos métodos MFD, MFDR e cMFDR.

Neste trabalho analisamos os desempenhos dos métodos MFD, MFDR e cMFDR com configuração manual do parâmetro $f$ e com configuração automática deste parâmetro, fornecida pelo método AFSA. Desejamos averiguar se a parametrização automática acarreta em diferenças nos desempenhos dos métodos.

\subsection{Fundamentação teórica}
\label{sec:fundamentacao}
%Seguindo o modelo sugerido no site, essa seção é obrigatória.

Na abordagem de aprendizagem de máquina, uma instância é representada como um vetor composto por pares de característica e valor.
Uma abordagem comum para a representação de textos na forma de vetores de características é a técnica conhecida como \emph{Bag of Words} (BoW)~\cite{guyon2003introduction}. Nela, um texto é tratado como um conjunto de palavras, sem considerar gramática ou ordem de ocorrência das palavras no texto.
Cada palavra do vocabulário da base de dados é considerada uma característica e é associada à frequência desta palavra no documento. Ou seja, o tamanho do vocabulário da base de dados define a dimensionalidade dos vetores.
Desta forma, em uma base de dados de tamanho médio, é comum que os vetores de características contenham dezenas de milhares de dimensões~\cite{gabrilovich2004text}. Entretanto, a maior parte destas características é irrelevante ou redundante. A alta dimensionalidade pode tornar a categorização de textos muito dispendiosa em termos de memória e tempo de execução.
Adicionalmente, este grande número de características pode impactar negativamente no desempenho de classificação, especialmente em bases de dados com um número pequeno de instâncias em relação ao número de características, fenômeno conhecido como ``praga da dimensionalidade''.
Como muitas das características são irrelevantes para a categorização, estes problemas podem ser tratados através da restrição da quantidade de características do conjunto de dados. Esta abordagem é conhecida como Redução de Dimensionalidade (DR, do inglês \emph{Dimensionality Reduction}).

Uma técnica de DR muito utilizada é a seleção de características. Nesta abordagem, o conjunto final é formado por parte das características do conjunto original. A utilização de métodos de filtragem é a técnica de FS considerada mais adequada para problemas de TC, devido ao custo computacional ser bem mais baixo que o de outras técnicas, como métodos \emph{wrapper}. Métodos de filtragem realizam um ordenamento das características através do uso de algoritmos determinísticos e métricas estatísticas, conhecidas com funções de avaliação de características (FEF, do inglês \emph{Feature Evaluation Function}). Após o ordenamento, uma quantidade, estabelecida pelo usuário, de características é selecionada para a formação do novo subconjunto.

\subsection{Métodos de seleção de características}
\label{sec:metodos}

\textit{Maximum f features per Document} (MFD)~\cite{mfd2014}, \textit{Maximum f features per Document-Reduced} (MFDR)~\cite{mfd2014} e \textit{Class-dependent Maximum f features per Document-Reduced} (cMFDR)~\cite{fragoso2016cmfdr} são métodos de seleção de características para categorização de texto.

MFD realiza a seleção local (por documento) das $f$ características consideradas mais relevantes, de acordo com alguma \textit{feature evaluation function}. O parâmetro $f$ é informado pelo usuário. MFDR introduz um limiar onde apenas documentos considerados relevantes são considerados na seleção de características. cMFDR aperfeiçoa o limiar introduzido por MFDR. Com cMFDR, existe um limiar para cada categoria, o que melhora o desempenho em bases de dados desbalanceadas.

Estes três métodos requerem um valor para o parâmetro $f$, que indica a quantidade de características a serem selecionadas por instância.
A escolha de um bom valor para este parâmetro pode ser um trabalho demorado e exaustivo.
Neste contexto, o método \textit{Automatic Feature Subsets Analyzer} (ASFA)~\cite{fragoso2016afsa} foi proposto para ser usado conjuntamente com um dos três métodos: MFD, MFDR ou cMFDR.
O objetivo do AFSA é prover, para estes métodos, um valor para o parâmetro $f$ de forma automática.

Esta seção apresentou conceitos básicos de categorização de textos e seleção de características e introduziu os métodos de seleção de características que são avaliados no trabalho. 
O restante do trabalho é organizado como segue: 
A Seção \ref{sec:objetivo} apresenta o objetivo do presente trabalho. 
Na Seção \ref{sec:exp} são detalhadas as configurações dos experimentos, incluindo descrição da base de dados, os algoritmos de interesse e as hipóteses a serem verificadas sobre os dados. 
A Seção \ref{sec:analise} demonstra os procedimentos estatísticos realizados no trabalho.
Finalmente, a Seção \ref{sec:conclusao} apresenta as conclusões do trabalho.

\section{Objetivo}
\label{sec:objetivo}

O objetivo desta pesquisa é verificar se o método AFSA é capaz de prover uma configuração para os métodos de seleção de características MFD, MFDR e cMFDR de modo que o desempenho de classificação não seja prejudicado. Ou seja, desejamos averiguar se o desempenho dos métodos MFD, MFDR e cMFDR é impactado quando estes métodos são usados conjuntamente com AFSA.
Esta análise visa determinar se os algoritmos possuem desempenhos significativamente diferentes.

%Para tanto, executamos análises estatísticas para avaliar a aderência dos dados amostrais a uma distribuição normal.
%Posteriormente, aplicamos testes de hipóteses adequados para, efetivamente, comparar os desempenho dos métodos.

\section{Experimentos}
\label{sec:exp}

Esta seção descreve as configurações dos experimentos realizados para gerar o conjunto de dados sobre o qual a análise será realizada.

\subsection{Base de dados}
\label{sec:bd}

Para a categorização de texto, foi utilizada a base de dados \textit{Reuters 10}.
Esta base de dados é um subconjunto da coleção \textit{Reuters-21578}~\footnote{Disponível em http://disi.unitn.it/moschitti/corpora.htm.}, que é uma das bases mais utilizadas em trabalhos de categorização de texto.
A base é composta por documentos coletados do \textit{Reuters newswire} de 1987 e apresenta 135 categorias.
Entretanto, o subconjunto adotado neste trabalho é composto pelas 10 maiores categorias da base.
O base de dados \textit{Reuters 10} contém 9.980 documentos e seu vocabulário abarca 10.987 termos.
A base de dados \textit{Reuters 10} também é muito utilizada em trabalhos de categorização de texto~\cite{chang2008multilabel,chen2009feature,yang2011new}. 

A distribuição dos documentos é bastante desbalanceada, apresentando categorias representando desde 2,3\% até 39\% do tamanho total da base. 
Nesta base foram aplicados os seguintes procedimentos de pré-processamento: \textit{stemming}, com o algoritmo \textit{Iterated Lovins Stemmer}~\cite{lovins1968development}, 
remoção de termos com duas ou menos letras e remoção de \textit{stopwords}.

Vale salientar que  a análise comparativa deste trabalho é realizada sobre o desempenho dos algoritmos, tendo a base citada como entrada, e não sobre características da base em si. O processo de geração das amostras utilizadas na análise estatística é detalhado na Seção~\ref{sec:metodologia}.

\subsection{Metodologia}
\label{sec:metodologia}

Conforme mencionado na Seção \ref{sec:objetivo}, esta pesquisa visa realizar uma comparação de desempenho de algoritmos de seleção de características para categorização de texto.
Neste trabalho, é feita uma avaliação do desempenho do método AFSA. Para tanto, AFSA é usado em conjunto com cada um dos métodos MFD, MFDR e cMFDR (conforme descrito na Seção~\ref{sec:metodos}. O desempenho de cada um dos métodos configurado manualmente é comparado com o desempenho destes métodos configurados automaticamente por AFSA.

O desempenho de um método de seleção de características pode ser auferido em termos de redução de dimensionalidade (tamanho do vetor final de características), tempo de execução e do desempenho de classificação atingido com o vetor de características resultante do processo de seleção. Neste trabalho, a avaliação dos desempenhos dos métodos levou em conta o desempenho de classificação sobre a base de dados resultante do processo de seleção de características. O algoritmo de aprendizagem de máquina empregado para a avaliação dos métodos foi classificador \textit{Na\"ive Bayes Multinomial}~\cite{mccallum1998comparison}. 

A base de dados \textit{Reuters 10} foi pré-processada utilizando cada um dos seis algoritmos de seleção de carcaterísticas (MFD, MFDR cMFDR e a combinação de cada um destes com AFSA), gerando, assim, seis versões da base original. Em seguida, o classificador \textit{Na\"ive Bayes Multinomial} foi treinado e testado com cada uma destas seis versões.

A validação cruzada estratificada foi utilizada como método para estimativa de desempenho.
Esta técnica é adotada para avaliar a capacidade de generalização de um modelo a partir de um conjunto de dados.
Neste trabalho utilizou-se a variação validação cruzada estratificada com \emph{10 folds}, na qual a base de dados $\mathcal{D}$ é particionada em 10 subconjuntos (\emph{folds}), de tamanhos semelhantes, mantendo a proporção de documentos por categorias equivalente à proporção encontrada no conjunto original. Então, são construídos 10 classificadores, cada um utilizando uma parcela dos \emph{folds} para treinamento e outra parcela para realizar o teste do mesmo, de modo a gerar diferentes combinações dos \emph{folds}~\cite{kohavi1995study}.

Nos experimentos realizados com os métodos MFD, MFDR e cMFDR, nove partições foram utilizadas para treinamento e uma partição foi utilizada para teste.
O método AFSA requer uma porção dos dados para configuração de seus parâmetreos. Assim, os experimentos executados com AFSA utilizaram oito partições para treinamento, uma para configuração de parâmetros/validação e uma para teste.
Deste modo, ao final deste processo, temos dez medidas de desempenho para cada um dos seis métodos de seleção de características avaliados.
Estes dados de desempenho correspondem às amostras que são entradas para as análises estatísticas realizadas neste trabalho.

A medida de desempenho utilizada nos experimentos foi \textit{Micro-F1}.
Seu cálculo é dado pela Eq.~\ref{eq:micro_f1}.

\begin{equation}
\operatorname{\mathcal{F}{1} = \frac{2 x \mathcal{P} x \mathcal{R}}{\mathcal{P} + \mathcal{R}}},
\label{eq:micro_f1}
\end{equation}

\noindent onde $\mathcal{P}$ é uma medida de precisão e $\mathcal{R}$ é uma medida de cobertura~\cite{chang2008multilabel}. As fórmulas para calcular a precisão $\mathcal{P}$ e a cobertura $\mathcal{R}$ são exibidas a seguir.

\begin{equation}
\operatorname{\mathcal{P}} = \frac{\sum_{j=1}^{C}TP_j}{\sum_{j=1}^{C}(TP_j + FP_j)}
\label{eq:precision}
\end{equation}

\begin{equation}
\operatorname{\mathcal{R}} = \frac{\sum_{j=1}^{C}TP_j}{\sum_{j=1}^{C}(TP_j + FN_j)}
\label{eq:recall}
\end{equation}

$TP_j$ é a quantidade de instâncias corretamente rotuladas como pertencentes à categoria $c_j$; $FP_j$ é a quantidade de instâncias incorretamente rotuladas como pertencentes à categoria $c_j$; e $FN_j$ é a quantidade de instâncias incorretamente rotuladas como não pertencentes à categoria $c_j$. 

\section{Análise estatística}
\label{sec:analise}

\subsection{Estatística descritiva}
\label{sec:estat_descr}

Uma boa prática ao iniciar uma análise de conjunto de dados, a qual é sugerida por muitos autores, é o uso de técnicas de estatística descritiva para se obter intuições iniciais acerca do conjunto de interesse \cite{montgomery2010applied}.

Para se ter uma indicação sobre os tipos de testes de hipótese que podem ser executados sobre os dados, é interessante verificar se as distribuições que geram as amostras apresentam normalidade.
A suposição de normalidade é útil pois, se esta for plausível, podemos aplicar testes paramétricos sobre os dados.
Testes paramétricos possuem maior poder estatístico do que seus equivalentes não-paramétricos, o que nos permite extrair conclusões mais fortes.

Para verificar a normalidade, começamos utilizando recursos visuais.
Histogramas permitem visualizar a disposição das amostras e consequentemente intuir sobre a distribuição da população geradora.
As Figuras~\ref{fig:hist_afsa_cmfdr} a~\ref{fig:hist_mfd} apresentam os histogramas com os desempenhos de classificação de cada algoritmo  nas suas versões combinadas com o ASFA e sem o mesmo.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_mfd.pdf}
	\caption{Histograma do desempenho de classificação do MFD (10 amostras).}
	\label{fig:hist_mfd}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_afsa_mfd.pdf}
	\caption{Histograma do desempenho de classificação do MFD com AFSA (10 amostras).}
	\label{fig:hist_afsa_mfd}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_mfdr.pdf}
	\caption{Histograma do desempenho de classificação do MFDR (10 amostras).}
	\label{fig:hist_mfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_afsa_mfdr.pdf}
	\caption{Histograma do desempenho de classificação do MFDR com AFSA (10 amostras).}
	\label{fig:hist_afsa_mfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_cmfdr.pdf}
	\caption{Histograma do desempenho de classificação do cMFDR (10 amostras).}
	\label{fig:hist_cmfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluehist_afsa_cmfdr.pdf}
	\caption{Histograma do desempenho de classificação do cMFDR (10 amostras).}
	\label{fig:hist_afsa_cmfdr}
\end{figure}

Observando os histogramas, não observamos indícios de normalidade em nenhuma das amostras.
Para juntar mais evidências, continuaremos a análise.

Outra ferramenta visual útil é o plot de probabilidade normal ou \textit{normplots}, que permite verificar o quão bem os dados representam uma distribuição normal.
A escala do gráfico é elaborada para que dados provenientes de uma distribuição normal ideal formem um reta que é usada como referência na figura.
Num cenário real, devido à presença de ruídos, não se espera que os dados se adequem perfeitamente à reta, porém se espera que, se os dados forem provenientes de uma distribuição normal, estes sejam bem aproximados pela reta de referência e estejam próximos a ela.
As Figuras \ref{fig:norm_mfd} a \ref{fig:norm_afsa_cmfdr} mostram os normplots de cada distribuição.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_mfd.pdf}
	\caption{Normplot desempenho de classificação do MFD (10 amostras).}
	\label{fig:norm_mfd}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_afsa_mfd.pdf}
	\caption{Normplot desempenho de classificação do MFD com AFSA (10 amostras).}
	\label{fig:norm_afas_mfd}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_mfdr.pdf}
	\caption{Normplot desempenho de classificação do MFDR (10 amostras).}
	\label{fig:norm_mfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_afsa_mfdr.pdf}
	\caption{Normplot desempenho de classificação do MFDR com AFSA (10 amostras).}
	\label{fig:norm_afsa_mfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_cmfdr.pdf}
	\caption{Normplot desempenho de classificação do cMFDR (10 amostras).}
	\label{fig:norm_cmfdr}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/bluenorm_afsa_cmfdr.pdf}
	\caption{Normplot desempenho de classificação do cMFDR com AFSA (10 amostras).}
	\label{fig:norm_afsa_cmfdr}
\end{figure}

Podemos observar que o fitting em geral não foi tão próximo quanto se poderia esperar.
Além disso, observa-se que nos valores mais extremos da distribuição, a aproximação degrada ainda mais (salvo pelo exemplo na Figura \ref{fig:norm_afsa_mfdr}).
\textcolor{green}{Isso pode indicar que estes pontos talvez sejam outliers, ou, o que consideramos mais provável, que as caudas da distribuição não são parecidas com a de uma normal}.

\textcolor{red}{Não vejo necessidade de apresentar este aqui. Acho que tem muita informação já. Opinem}
Ainda recorremos aos diagramas de caixa (Figura \ref{fig:boxplot}) como um último recurso visual. 
Nestes podemos verificar sobretudo a simetria das amostras.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/blueboxplot.pdf}
	\caption{\textcolor{red}{Escrever uma descrição}.}
	\label{fig:boxplot}
\end{figure}

Observando os diagramas, vemos que quase todos são assimétricos, alguns inclusive apresentando assimetria acentuada.

\textcolor{red}{As amostras pequenas se mostraram um fator limitante da análise...}

Além dos recursos gráficos, podemos analisar diretamente os sumários numéricos dos dados.
Ao comparar médias e medianas, podemos ter uma idéia da simetria do conjunto em questão.
A Tabela \ref{tab:est_descr} mostra os valores de média, mediana e desvio padrão de cada conjunto.
\textcolor{red} {O problema é que esse desvio padrão tá meio solto aí. Não vai ser referenciado pra nada.. Acho que ou apresenta essa tabela, ou o boxplot, talvez até nenhum dos dois. Comentem.}

\begin{table}[h]
	\centering
	\caption{Sumários numéricos dos dados}
	\label{tab:est_descr}
	\begin{tabular}{c|ccc}
		Método    	& Média  	& Mediana 	& Desv. Padrão  \\
		\hline
		AFSA cMFDR 	& 81.58 	& 81.50 	& 0.97 \\
		cMFDR 		& 81.34 	& 81.30		& 0.88 \\
		AFSA MFDR 	& 80.16 	& 80.23 	& 1.10 \\
		MFDR 		& 80.06 	& 79.94 	& 1.05 \\
		AFSA MFD 	& 81.72 	& 81.95 	& 0.92 \\
		MFD 		& 81.78 	& 81.95 	& 0.82 \\
		\hline
	\end{tabular}
\end{table}

\textcolor{red}{FALAR SOBRE OS RESULTADOS
Quais aparentam ser normais (média aprox. igual à mediana)
}

%\textcolor{red}{FAZER UMA CONCLUSÃO DA SEÇÃO
%Falar das impressões sobre a normalidade dos dados com bases nos histogramas, boxplot e medidas estatísticas.......}

\subsection{Testes de aderência}

Uma maneira mais formal de verificar se as amostras seguem uma distribuição normal é com o uso de testes de aderência.
Nesta pesquisa, foram executados os testes Shapiro-Wilk~\cite{shapiro1965analysis}, Anderson-Darling~\cite{anderson1954test} e Cramer-von Mises~\cite{durbin1972components}.
Os resultados dos testes para cada amostra são apresentados na tabela~\ref{tab:aderencia}.

\begin{table}[h]
	\centering
	\caption{Resultados dos testes de aderência.}
	\label{tab:aderencia}
	\begin{tabular}{c|ccc}
		\hline
		& \multicolumn{3}{c}{\textit{p-value}}      \\
		\cline{2-4}
						& Shapiro-Wilk 	& Anderson-Darling  & Cramer-von Mises\\
		\hline
		AFSA cMFDR		& 0.75       	& 0.67           	& 0.74 \\
		cMFDR 			& 0.90       	& 0.86          	& 0.86 \\
		AFSA MFDR  		& 0.88       	& 0.89          	& 0.87 \\
		MFDR  			& 0.61       	& 0.47            	& 0.45 \\
		AFSA MFD   		& 0.19       	& 0.25          	& 0.30 \\
		MFD   			& 0.88       	& 0.77          	& 0.72 \\
		\hline
	\end{tabular}
\end{table}

Consideramos que uma amostra não segue uma distribuição normal caso o \textit{p-value} seja menor que 0.05.
Deste modo, o resultado dos três testes apontam que, para todas as amostras, não existem evidências suficientes para rejeitar a hipótese nula de que a amostra segue uma distribuição normal, reforçando a impressão obtida da análise dos valores das médias e medianas das amostras~\ref{sec:estat_descr}.
Porém é importante salientar que a eficiências de testes de aderência (não paramétricos) é muito prejudicada quando as amostras são pequenas, como no nosso caso.
Adicionalmente, a análise dos histogramas, normplots e dos boxplots (da maioria das amostras) dão indícios de que as amostras não seguem uma distribuição normal.
Por estas razões, concluímos que, com os dados disponíveis, não temos segurança em afirmar que as amostras seguem uma distribuição normal.
Diante disto, utilizaremos teste de hipótese não-paramétrico para verificar a existência de diferenças significativas entre as amostras.

\subsection{Resultados}

Depois de avaliar as distribuições das amostras, optamos pelo caminho mais seguro que consiste na comparação dos pares de métodos por testes não paramétricos. 
Como as comparações a serem executadas são entre pares de algoritmos, optamos pelo teste de sinais com postos de Wilcoxon \cite{wilcoxon1945individual}.

Estabelecemos a hipótese nula de que os desempenhos dos métodos sendo comparados (com e sem AFSA) são iguais, a hipótese alternativa é que os desempenhos são diferentes. Com esta hipótese, buscamos averiguar se a configuração paramétrica realizada automáticamente por AFSA apresenta algum impacto no desempenho de classificação.

Os resultados dos testes são apresentados na Tabela 
\ref{tab:rank_sum}.

\begin{table}[h]
	\centering
	\caption{Resultados dos testes de hipóteses Wilcoxon.}
	\label{tab:rank_sum}
	\begin{tabular}{c|c}
		\hline
		Hipótese alternativa							& \textit{p-value}\\
		\hline
		$H_1:$ AFSA MFD $\neq$ MFD   			& 0.44    \\
		$H_1:$ AFSA MFDR  $\neq$ MFDR			& 0.54    \\
		$H_1:$ AFSA cMFDR $\neq$ cMFDR			& 0.08    \\
		\hline
	\end{tabular}
\end{table}

Para este teste, consideramos um nível de significância de 0.05. Assim, diante dos resultados apresentados na Tabela~\ref{tab:rank_sum}, chegamos à conclusão de que não há indícios suficientes para afirmar que a configuração automática de parâmetros realizada pelo método AFSA impacta no desempenho classificatório dos métodos MFD, MFDR e cMFDR. 

\section{Conclusão}
\label{sec:conclusao}
\textcolor{red}{Completar.}
Percebemos que para que a análise seja mais completa, se faz necessário uma amostra maior.
Vale salientar que embora o resultado do teste seja inconclusivo para as duas amostras, ele fortalece a intuição de que não há diferenças significativas de fato.
\textcolor{red}{Completar.}


\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
% \bibliography{IEEEabrv,../bib/paper}
\bibliography{bb}

\end{document}
